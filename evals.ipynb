{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd2/sonia/miniconda3/envs/great/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, pipeline, ensemble, compose\n",
    "import datasets\n",
    "import os\n",
    "\n",
    "# cols = ['age', 'workclass', 'fnlwgt', 'income']\n",
    "\n",
    "real_path = '/hdd3/sonia/data/adult.csv'\n",
    "dgpt2_path = '/hdd3/sonia/be_great/ckpts/dgpt2/adult-allcol/samples.csv'\n",
    "moe_path = '/hdd3/sonia/be_great/ckpts/moe/dgpt2/adult-allcol/jul21/samplesclean.csv'\n",
    "greatdpt2_path = '/hdd3/sonia/be_great/ckpts/dgpt2-greatclean.csv'\n",
    "moegreatdgpt2_path = '/hdd3/sonia/be_great/ckpts/great/adult/moegreatdgpt2-aug01.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 15) (5935, 15) (9106, 15) (9815, 15) (3993, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3993, 15), (3993, 15), (3993, 15), (3993, 15), (3993, 15))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = pd.read_csv(real_path)#[cols]\n",
    "dgpt2= pd.read_csv(dgpt2_path)\n",
    "moe  = pd.read_csv(moe_path)\n",
    "greatdgpt2=pd.read_csv(greatdpt2_path)\n",
    "moegreatdgpt2=pd.read_csv(moegreatdgpt2_path)\n",
    "print(real.shape, dgpt2.shape, moe.shape, greatdgpt2.shape, moegreatdgpt2.shape)\n",
    "\n",
    "rs = 2\n",
    "min_dataset_size = min(len(real), len(dgpt2), len(moe), len(greatdgpt2), len(moegreatdgpt2))\n",
    "real = real.sample(min_dataset_size, random_state=rs)\n",
    "dgpt2=dgpt2.sample(min_dataset_size, random_state=rs)\n",
    "moe  =  moe.sample(min_dataset_size, random_state=rs)\n",
    "greatdgpt2 = greatdgpt2.sample(min_dataset_size, random_state=rs)\n",
    "moegreatdgpt2=moegreatdgpt2.sample(min_dataset_size, random_state=rs)\n",
    "real.shape, dgpt2.shape, moe.shape, greatdgpt2.shape, moegreatdgpt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['real', 'dgpt2', 'moe', 'greatdgpt2', 'moegreatdgpt2'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {'real':real, 'dgpt2':dgpt2, 'moe':moe, 'greatdgpt2':greatdgpt2, 'moegreatdgpt2':moegreatdgpt2}\n",
    "datadict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real\n",
      "dgpt2\n",
      "moe\n",
      "greatdgpt2\n",
      "moegreatdgpt2\n"
     ]
    }
   ],
   "source": [
    "ords = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "        'relationship', 'race', 'sex', 'native-country'] # MUST BE IN ORDER\n",
    "nums = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', ]\n",
    "labs = ['income']\n",
    "\n",
    "for k, v in datadict.items():\n",
    "    print(k)\n",
    "    datadict[k] = datadict[k][ords+nums+labs] # ensure they're in order\n",
    "\n",
    "# for each ord column, get all unique values occurign in real/synth, train/test\n",
    "categories = []\n",
    "for name in ords:\n",
    "    s = set(real[name].unique().tolist())\n",
    "    s.update(dgpt2[name].unique().tolist())\n",
    "    s.update(moe[name].unique().tolist())\n",
    "    s.update(greatdgpt2[name].unique().tolist())\n",
    "    \n",
    "    categories.append( list(s) )\n",
    "categories\n",
    "\n",
    "ordenc = preprocessing.OrdinalEncoder(categories=categories)\n",
    "numenc = preprocessing.StandardScaler()\n",
    "lb = preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(trainset):\n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=10, max_depth=4)\n",
    "    preprocessing_pipeline = compose.ColumnTransformer([\n",
    "        (\"ordinal_preprocessor\", ordenc, ords),\n",
    "        (\"numerical_preprocessor\", numenc, nums),\n",
    "    ])\n",
    "    complete_pipeline = pipeline.Pipeline([\n",
    "        (\"preprocessor\", preprocessing_pipeline),\n",
    "        (\"estimator\", rfc)\n",
    "    ])\n",
    "    \n",
    "    preprocessed_labels = lb.fit_transform(trainset[labs].values.ravel()).ravel()\n",
    "    complete_pipeline.fit(trainset[ords+nums], preprocessed_labels)\n",
    "    return complete_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real\n",
      "dgpt2\n",
      "moe\n",
      "greatdgpt2\n",
      "moegreatdgpt2\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# create random forest pipelines\n",
    "rfdict = {}\n",
    "for src in datadict.keys():\n",
    "    print(src)\n",
    "    rfdict[src] = create_pipeline(datadict[src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real on real: \t\t\t0.8494866015527173\n",
      "dgpt2 on real: \t\t\t0.8016528925619835\n",
      "moe on real: \t\t\t0.8146756824442775\n",
      "greatdgpt2 on real: \t\t\t0.8196844477836214\n",
      "moegreatdgpt2 on real: \t\t\t0.8254445279238668\n",
      "real on dgpt2: \t\t\t0.639869772101177\n",
      "dgpt2 on dgpt2: \t\t\t0.7751064362634611\n",
      "moe on dgpt2: \t\t\t0.7420485850237917\n",
      "greatdgpt2 on dgpt2: \t\t\t0.7325319308790383\n",
      "moegreatdgpt2 on dgpt2: \t\t\t0.7145003756574004\n",
      "real on moe: \t\t\t0.6378662659654395\n",
      "dgpt2 on moe: \t\t\t0.7738542449286251\n",
      "moe on moe: \t\t\t0.7986476333583772\n",
      "greatdgpt2 on moe: \t\t\t0.7458051590282995\n",
      "moegreatdgpt2 on moe: \t\t\t0.7743551214625595\n",
      "real on greatdgpt2: \t\t\t0.7518156774355121\n",
      "dgpt2 on greatdgpt2: \t\t\t0.8064112196343601\n",
      "moe on greatdgpt2: \t\t\t0.7953919358878037\n",
      "greatdgpt2 on greatdgpt2: \t\t\t0.8131730528424743\n",
      "moegreatdgpt2 on greatdgpt2: \t\t\t0.8029050838968195\n",
      "real on moegreatdgpt2: \t\t\t0.7721011770598547\n",
      "dgpt2 on moegreatdgpt2: \t\t\t0.8564988730277987\n",
      "moe on moegreatdgpt2: \t\t\t0.8692712246431255\n",
      "greatdgpt2 on moegreatdgpt2: \t\t\t0.8407212622088656\n",
      "moegreatdgpt2 on moegreatdgpt2: \t\t\t0.8762834961182069\n"
     ]
    }
   ],
   "source": [
    "for data in datadict.keys():\n",
    "    labels = lb.fit_transform(datadict[data][labs])\n",
    "    for model in rfdict.keys():\n",
    "        score = rfdict[model].score(datadict[data][ords+nums], labels)\n",
    "        print(f'{model} on {data}: \\t\\t\\t{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
