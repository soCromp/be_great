{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, pipeline, ensemble, compose\n",
    "import datasets\n",
    "import os\n",
    "\n",
    "# cols = ['age', 'workclass', 'fnlwgt', 'income']\n",
    "\n",
    "real_path = '/hdd3/sonia/data/adult.csv'\n",
    "dgpt2_path = '/hdd3/sonia/be_great/ckpts/dgpt2/adult-allcol/samples.csv'\n",
    "moe_path = '/hdd3/sonia/be_great/ckpts/moe/dgpt2/adult-allcol/jul21/samplesclean.csv'\n",
    "greatdpt2_path = '/hdd3/sonia/be_great/ckpts/dgpt2-greatclean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 15) (5935, 15) (9106, 15) (9815, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5935, 15), (5935, 15), (5935, 15), (5935, 15))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = pd.read_csv(real_path)#[cols]\n",
    "dgpt2= pd.read_csv(dgpt2_path)\n",
    "moe  = pd.read_csv(moe_path)\n",
    "greatdgpt2=pd.read_csv(greatdpt2_path)\n",
    "print(real.shape, dgpt2.shape, moe.shape, greatdgpt2.shape)\n",
    "\n",
    "rs = 2\n",
    "min_dataset_size = min(len(real), len(dgpt2), len(moe), len(greatdgpt2))\n",
    "real = real.sample(min_dataset_size, random_state=rs)\n",
    "dgpt2=dgpt2.sample(min_dataset_size, random_state=rs)\n",
    "moe  =  moe.sample(min_dataset_size, random_state=rs)\n",
    "greatdgpt2 = greatdgpt2.sample(min_dataset_size, random_state=rs)\n",
    "real.shape, dgpt2.shape, moe.shape, greatdgpt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['real', 'dgpt2', 'moe', 'greatdgpt2'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {'real':real, 'dgpt2':dgpt2, 'moe':moe, 'greatdgpt2':greatdgpt2}\n",
    "datadict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ords = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "        'relationship', 'race', 'sex', 'native-country', 'income'] # MUST BE IN ORDER\n",
    "nums = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', ]\n",
    "labs = ['income']\n",
    "\n",
    "# for each ord column, get all unique values occurign in real/synth, train/test\n",
    "categories = []\n",
    "for name in ords:\n",
    "    s = set(real[name].unique().tolist())\n",
    "    s.update(dgpt2[name].unique().tolist())\n",
    "    s.update(moe[name].unique().tolist())\n",
    "    s.update(greatdgpt2[name].unique().tolist())\n",
    "    \n",
    "    categories.append( list(s) )\n",
    "categories\n",
    "\n",
    "ordenc = preprocessing.OrdinalEncoder(categories=categories)\n",
    "numenc = preprocessing.StandardScaler()\n",
    "lb = preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(trainset):\n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=10, max_depth=4)\n",
    "    preprocessing_pipeline = compose.ColumnTransformer([\n",
    "        (\"ordinal_preprocessor\", ordenc, ords),\n",
    "        (\"numerical_preprocessor\", numenc, nums),\n",
    "    ])\n",
    "    complete_pipeline = pipeline.Pipeline([\n",
    "        (\"preprocessor\", preprocessing_pipeline),\n",
    "        (\"estimator\", rfc)\n",
    "    ])\n",
    "    \n",
    "    preprocessed_labels = lb.fit_transform(trainset[labs].values.ravel()).ravel()\n",
    "    complete_pipeline.fit(trainset[ords+nums], preprocessed_labels)\n",
    "    return complete_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real\n",
      "dgpt2\n",
      "moe\n",
      "greatdgpt2\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# create random forest pipelines\n",
    "rfdict = {}\n",
    "for src in datadict.keys():\n",
    "    print(src)\n",
    "    rfdict[src] = create_pipeline(datadict[src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real on real: \t\t\t0.9826453243470935\n",
      "dgpt2 on real: \t\t\t0.010278011794439764\n",
      "moe on real: \t\t\t0.27363100252737993\n",
      "greatdgpt2 on real: \t\t\t0.32299915754001685\n",
      "real on dgpt2: \t\t\t0.3467565290648694\n",
      "dgpt2 on dgpt2: \t\t\t0.9976411120471778\n",
      "moe on dgpt2: \t\t\t0.9816343723673125\n",
      "greatdgpt2 on dgpt2: \t\t\t0.9511373209772536\n",
      "real on moe: \t\t\t0.3363100252737995\n",
      "dgpt2 on moe: \t\t\t0.998989048020219\n",
      "moe on moe: \t\t\t0.9939342881213142\n",
      "greatdgpt2 on moe: \t\t\t0.9755686604886268\n",
      "real on greatdgpt2: \t\t\t0.4306655433866891\n",
      "dgpt2 on greatdgpt2: \t\t\t1.0\n",
      "moe on greatdgpt2: \t\t\t0.9962931760741365\n",
      "greatdgpt2 on greatdgpt2: \t\t\t0.9885425442291491\n"
     ]
    }
   ],
   "source": [
    "for data in datadict.keys():\n",
    "    labels = lb.fit_transform(datadict[data][labs])\n",
    "    for model in rfdict.keys():\n",
    "        score = rfdict[model].score(datadict[data][ords+nums], labels)\n",
    "        print(f'{model} on {data}: \\t\\t\\t{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
